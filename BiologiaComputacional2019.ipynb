{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BiologiaComputacional2019.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IgorSouza21/SecundaryStructurePrediction/blob/master/BiologiaComputacional2019.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSU_5Cq7TF8X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuDpR8wDgL9l",
        "colab_type": "text"
      },
      "source": [
        "#Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ljxGUbcgOTE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.optimizers import SGD\n",
        "import gc\n",
        "!pip install -q SwarmPackagepy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zG-JyilzDp1h",
        "colab_type": "text"
      },
      "source": [
        "#Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfDwS85qTW6l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import numpy as np\n",
        "import glob\n",
        "import pickle\n",
        "import pandas as pd\n",
        "\n",
        "def create_base(base, window, path):\n",
        "    res = base[\"RES\"]\n",
        "    dssp = base[\"DSSP\"]\n",
        "\n",
        "    for r in res:\n",
        "        t = 1\n",
        "\n",
        "    for i in glob.glob(path):\n",
        "        f = open(i, \"r\")\n",
        "        x = f.readlines()\n",
        "        f.close()\n",
        "        prot = \"0,\"\n",
        "        prot += x[0].split(\"RES:\")[1]\n",
        "        prot = prot.split(\",\")\n",
        "        prot.insert(len(prot)-1, \"0\")\n",
        "        prot.pop()\n",
        "        new_prot = []\n",
        "        for p in range(len(prot)):\n",
        "            new_prot.append(prot[p:p+3])\n",
        "        dssp = (x[1].split(\"DSSP:\")[1]).split(\",\")\n",
        "        base.append(tuple(zip(new_prot, dssp)))\n",
        "    return base"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raDFhRQIDrEV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conversion8to3(value):\n",
        "    #     helix (G, H and I), strand (E and B) and loop (S, T, and _)\n",
        "    c = {\"H\": [\"G\", \"H\", \"I\"], \"S\": [\"E\", \"B\"], \"_\": [\"S\", \"T\", \"_\", \"?\"]}\n",
        "    for t in c.items():\n",
        "        if value in t[1]:\n",
        "            return t[0]\n",
        "\n",
        "    print(value)\n",
        "\n",
        "\n",
        "def loadfolderproteins(path):\n",
        "    base = pd.DataFrame()\n",
        "    res = []\n",
        "    dssp8 = []\n",
        "    dssp3 = []\n",
        "    for i in glob.glob(path):\n",
        "        f = open(i, \"r\")\n",
        "        x = f.readlines()\n",
        "        f.close()\n",
        "        prot = x[0].split(\"RES:\")[1]\n",
        "        prot = prot.split(\",\")\n",
        "        prot.pop()\n",
        "        res.append(\"\".join(prot))\n",
        "        lb = x[1].split(\"DSSP:\")[1]\n",
        "        lb = lb.split(\",\")\n",
        "        lb.pop()\n",
        "        lb3 = [conversion8to3(bl) for bl in lb]\n",
        "        dssp8.append(\"\".join(lb))\n",
        "        dssp3.append(\"\".join(lb3))\n",
        "\n",
        "    base[\"RES\"] = res\n",
        "    base['DSSP8'] = dssp8\n",
        "    base['DSSP3'] = dssp3\n",
        "    base.to_csv(\"NewCB513.csv\", index=False)\n",
        "\n",
        "\n",
        "def load(X, size, window, class=\"DSSP8\"):\n",
        "    data = X['RES']\n",
        "    classes = X[class]\n",
        "    positions = {'A':1,'C':2,'D':3,'E':4,'F':5,'G':6,'H':7,'I':8,'K':9,'L':10,'M':11,'N':12,\n",
        "                 'P':13,'Q':14,'R':15,'S':16,'T':17,'V':18,'W':19,'Y':20}\n",
        "#     classes_converter = {'-': 0, 'E':1, 'H':2}\n",
        "    res = []\n",
        "    for i in range(len(data)):\n",
        "        for j in range(len(data[i])):\n",
        "            res.append(int(positions[data[i][j]]))\n",
        "    for i in range(size):\n",
        "        res.insert(0, 0)\n",
        "        res.append(0)\n",
        "    data =[]\n",
        "    for i in range(len(X['prot'])):\n",
        "        data.append(res[i:window + i])\n",
        "        data[i].append(classes[i])\n",
        "#         data[i].append(classes_converter[classes[i]])\n",
        "    columns = [[]]*(window + 1)\n",
        "    for i in range(window):\n",
        "        columns[i] = \"Element\" + str(i)\n",
        "    columns[window] = 'Class'\n",
        "    data = pd.DataFrame(data, columns = columns)\n",
        "    \n",
        "    return data\n",
        "\n",
        "\n",
        "def load_data(window):\n",
        "    size = int(window/2)\n",
        "    proteins = pd.read_csv('NewCB513.csv')\n",
        "    res = load(proteins.iloc[0], size, window)\n",
        "    for i in range(1,len(proteins)):\n",
        "        aux = load(proteins.iloc[i], size, window)\n",
        "        res = res.append(aux,ignore_index = True)\n",
        "        \n",
        "    X = res.drop(['Class'], axis=1)\n",
        "    y = res['Class']\n",
        "    return X, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOzrbTmLpGPW",
        "colab_type": "text"
      },
      "source": [
        "#Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyCbvAvzpHba",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def amostra_estrat(tam , df , classe):\n",
        "    classes = df[classe].unique()\n",
        "    qtde_por_classe = round(tam / len(classes))\n",
        "    amostras_por_classe = []\n",
        "    for c in classes:\n",
        "        indices_c = df[classe] == c\n",
        "        obs_c = df[indices_c]\n",
        "        amostra_c = obs_c.sample(qtde_por_classe)\n",
        "        amostras_por_classe.append(amostra_c)\n",
        "    amostra_estratificada = pd.concat(amostras_por_classe)\n",
        "    return amostra_estratificada\n",
        "  \n",
        "\n",
        "arrayfitnessGWO = []\n",
        "  \n",
        "def fitnessGWO(chromossome,Xtrain,ytrain,Xval,yval):\n",
        "    \n",
        "    w1 = np.split(np.array(chromossome[0:len(chromossome)-6]), 50)\n",
        "    w2 = np.reshape(chromossome[len(chromossome)-7:len(chromossome)-1], (6, 1))\n",
        "\n",
        "    model.get_layer('dense1').set_weights((np.array(w1), np.zeros(6)))\n",
        "    model.get_layer('dense2').set_weights((np.array(w2), np.zeros(1)))\n",
        "    model.fit(Xtrain, ytrain, epochs=20, batch_size=256, verbose = False)\n",
        "    retorno = model.evaluate(Xval,yval, verbose = False)\n",
        "\n",
        "    if len(arrayfitnessGWO) == 0:\n",
        "        model_json = model.to_json()\n",
        "        with open(\"modelGWO.json\", \"w\") as json_file:\n",
        "            json_file.write(model_json)\n",
        "        model.save_weights(\"modelGWO.h5\")\n",
        "\n",
        "    atual = retorno[1]\n",
        "\n",
        "    if len(arrayfitnessGWO) > 1:\n",
        "        if atual > arrayfitnessGWO[np.argmax(arrayfitnessGWO)]:\n",
        "        model_json = model.to_json()\n",
        "        with open(\"modelGWO.json\", \"w\") as json_file:\n",
        "            json_file.write(model_json)\n",
        "            model.save_weights(\"modelGWO.h5\")\n",
        "\n",
        "    arrayfitnessGWO.append(atual)\n",
        "\n",
        "    return atual\n",
        "\n",
        "def loadmodelGWO():\n",
        "    json_file = open('modelGWO.json', 'r')\n",
        "    loaded_model_json = json_file.read()\n",
        "    json_file.close()\n",
        "    loaded_model = model_from_json(loaded_model_json)\n",
        "    loaded_model.load_weights(\"modelGWO.h5\")\n",
        "    loaded_model.compile( loss='binary_crossentropy', optimizer=\"adam\", \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "    return loaded_model\n",
        "\n",
        "\n",
        "from SwarmPackagePy.intelligence import sw\n",
        "\n",
        "\n",
        "class gwo(sw):\n",
        "\n",
        "    def __init__(self, n, function, lb, ub, dimension, iteration,Xtrain,ytrain,Xval,yval,init = None):\n",
        "\n",
        "\n",
        "        super(gwo, self).__init__()\n",
        "\n",
        "        if init is None:\n",
        "            self.__agents = np.random.uniform(lb, ub, (n, dimension))\n",
        "        else:\n",
        "            self.__agents = np.array(init)\n",
        "            \n",
        "        self._points(self.__agents)\n",
        "        alpha, beta, delta = self.__get_abd(n, function,Xtrain,ytrain,Xval,yval)\n",
        "\n",
        "        Gbest = alpha\n",
        "\n",
        "        for t in range(iteration):\n",
        "\n",
        "            a = 2 - 2 * t / iteration\n",
        "\n",
        "            r1 = np.random.random((n, dimension))\n",
        "            r2 = np.random.random((n, dimension))\n",
        "            A1 = 2 * r1 * a - a\n",
        "            C1 = 2 * r2\n",
        "\n",
        "            r1 = np.random.random((n, dimension))\n",
        "            r2 = np.random.random((n, dimension))\n",
        "            A2 = 2 * r1 * a - a\n",
        "            C2 = 2 * r2\n",
        "\n",
        "            r1 = np.random.random((n, dimension))\n",
        "            r2 = np.random.random((n, dimension))\n",
        "            A3 = 2 * r1 * a - a\n",
        "            C3 = 2 * r2\n",
        "\n",
        "            Dalpha = abs(C1 * alpha - self.__agents)\n",
        "            Dbeta = abs(C2 * beta - self.__agents)\n",
        "            Ddelta = abs(C3 * delta - self.__agents)\n",
        "\n",
        "            X1 = alpha - A1 * Dalpha\n",
        "            X2 = beta - A2 * Dbeta\n",
        "            X3 = delta - A3 * Ddelta\n",
        "            self.__agents = (X1 + X2 + X3) / 3\n",
        "\n",
        "            self.__agents = np.clip(self.__agents, lb, ub)\n",
        "            self._points(self.__agents)\n",
        "\n",
        "            alpha, beta, delta = self.__get_abd(n, function,Xtrain,ytrain,Xval,yval)\n",
        "            if function(alpha,Xtrain,ytrain,Xval,yval) > function(Gbest,Xtrain,ytrain,Xval,yval):\n",
        "                Gbest = alpha\n",
        "\n",
        "        self._set_Gbest(Gbest)\n",
        "        alpha, beta, delta = self.__get_abd(n, function,Xtrain,ytrain,Xval,yval)\n",
        "        self.__leaders = list(alpha), list(beta), list(delta)\n",
        "\n",
        "    def __get_abd(self, n, function,Xtrain,ytrain,Xval,yval):\n",
        "\n",
        "        result = []\n",
        "        fitness = [(function(self.__agents[i],Xtrain,ytrain,Xval,yval), i) for i in range(n)]\n",
        "        fitness.sort(reverse=True)\n",
        "\n",
        "        for i in range(3):\n",
        "            result.append(self.__agents[fitness[i][1]])\n",
        "\n",
        "        return result\n",
        "\n",
        "    def get_leaders(self):\n",
        "\n",
        "        return list(self.__leaders)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-KvJBoSA5NR",
        "colab_type": "text"
      },
      "source": [
        "#Main"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-KLQ-3KA6wZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ite = 35    # Quantidade de gerações dos algoritmos evolutivos \n",
        "iteKfold = 5 # Quantidade de iterações que vai ser executado o cross validation de k = 10\n",
        "scoresfinalMLP = [] # Array para salvar os score de validação da MLP\n",
        "cont = 0 # Seed para o shuffle da base de dados\n",
        "popu = 10 # Tamanho da população\n",
        "kvalue = 10\n",
        "\n",
        "testGWO = []\n",
        "\n",
        "k = KFold(kvalue,True,1) # Instancia da classe Kfold com k = 10\n",
        "\n",
        "for x in range(iteKfold): # For da quantidade de vezes que ira ser executado o cross validation de k = 10\n",
        "\n",
        "    for train_index,test_index in k.split(dataset): # For do Kfold com K = 10\n",
        "        X_train, X_test = np.array(dataset)[train_index], np.array(dataset)[test_index] # Separando o conjunto de Treino separado a cima em treino e validação\n",
        "        y_train, y_test = np.array(labels)[train_index], np.array(labels)[test_index] # Separando o conjunto de Treino separado a cima em treino e validação\n",
        "\n",
        "        X_trainK, X_valK, y_trainK, y_valK = train_test_split(X_train, y_train, test_size=0.2)\n",
        "\n",
        "\n",
        "        ############ CREATE POPU ######\n",
        "\n",
        "        inicialpopulation = np.array(creatpopuMSRA(popu,306)) # Criando a população inicial\n",
        "        inicialstd = np.array(creatpopuSTD(popu,306)) # Criando a população de desvio padrões iniciais\n",
        "        sizepop = inicialpopulation.shape[0] # Tamanho da população\n",
        "        dimpop = inicialpopulation.shape[1] # Dimensão da população\n",
        "\n",
        "        ############ CREATE POPU #########\n",
        "\n",
        "        ######## MLP ############\n",
        "\n",
        "        timeinicialMLP = time.time() # Instanciando o tempo de inicio da execução do MLP\n",
        "        modelMLP = Sequential() # Instanciando o modelo\n",
        "        modelMLP.add(Dense(6, input_dim = 50, activation=\"relu\")) # Instanciando o modelo\n",
        "        modelMLP.add(Dense(1, activation=\"sigmoid\")) # Instanciando o modelo\n",
        "        modelMLP.compile( loss='binary_crossentropy', optimizer=\"adam\",metrics=['accuracy']) # Instanciando o modelo\n",
        "\n",
        "        modelMLP.fit(X_trainK, y_trainK, epochs=20, batch_size=256, verbose = False) # Treinando o modelo\n",
        "        scoresfinalMLP.append(modelMLP.evaluate(X_valK,y_valK,verbose = False)[1]) # Avaliando o modelo com o conjunto de validação e guardando no array de validações\n",
        "\n",
        "        timefinalMLP = time.time() # pegando o tempo de termino\n",
        "        timeMLP.append(timefinalMLP-timeinicialMLP) # Salvando o tempo de execução\n",
        "    \n",
        "    \n",
        "    ################ GWO ############################\n",
        "    \n",
        "    timeinicialgwo = time.time()\n",
        "    grey = gwo(sizepop,fitnessGWO,-1,1,dimpop,ite,X_trainK,y_trainK,X_valK,y_valK,init=inicialpopulation.copy(),)# Rodando o GWO com os conjuntos de validação e treinamento e com o número\n",
        "                                                                                                          # de iterações declaradas no inicio\n",
        "    timefinalgwo = time.time()\n",
        "    timeGWO.append(timefinalgwo - timeinicialgwo)\n",
        "        \n",
        "    \n",
        "    modelGWO = loadmodelGWO() # Carregando o melhor modelo gerado pelo GWO para teste\n",
        "      \n",
        "    testGWO.append(modelGWO.evaluate(X_test,y_test, verbose = False)[1]) # Avaliando o melhor modelo do GWO com o conjunto de teste\n",
        "\n",
        "    arrayfitnessGWO = []\n",
        "\n",
        "    dataset, labels = shuffle(dataset, labels, random_state=cont) # Depois que termina as 10 iterações de um Kfold dou shuffle\n",
        "    cont += 1 # Valor da seed do shufle sendo somado +1\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}